{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the path to fetch the data.  We assume that the JSON file we need is in a different folder laballed data\n",
    "cwd = Path.cwd()\n",
    "rel_path = '../data/'\n",
    "mod_path = Path('Full_Dataset_Normalizer.ipynb').parent\n",
    "src_path_1 = (mod_path / rel_path).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Universal Variables\n",
    "imagetags = set() #All image tags found by the API\n",
    "hashtags = set() #All hashtags used by all the photos\n",
    "imageobjects = set() #All the objects found by the API\n",
    "imagecolors = set() #All the top 3 colors found by the API\n",
    "fieldnames = ['PageName', 'PostID', 'PostTime', 'Height', 'Width', 'Followers', 'Comments', 'Likes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Column_Headers(imagetags, hashtags, imageobjects, imagecolors):\n",
    "    with open(str(src_path_1)+'\\\\cortex-travel-industry-metadata-updated.json', mode = 'r', encoding = 'utf-8') as f:\n",
    "        data = json.loads(f.read(), encoding = 'utf-8') #Load the data file\n",
    "    #Get all the column header names from the data\n",
    "    for photo in data: #Loop through every photo in the data set\n",
    "        md = photo['metadata'] #The photo's metadata\n",
    "        tags = md.get('imageTags', '') #The photo's image tags by the API\n",
    "        ht = md.get('hashtags', '') #The photo's hash tags by the user\n",
    "        objects = md.get('imageObjects','') #Objects in the photo found by the API\n",
    "        colors = md.get('imageColors','') #The 3 main colors in the photo found by the API\n",
    "        #Add the info found in the photo into the sets\n",
    "        for tag in tags:\n",
    "            imagetags.add(tag['value'])\n",
    "        for tag in ht:\n",
    "            hashtags.add(tag)\n",
    "        for obj in objects:\n",
    "            imageobjects.add(obj['name'])\n",
    "        for color in colors:\n",
    "            imagecolors.add(color['value'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Tag_Data(fieldnames, data, imagetags):\n",
    "    fn = fieldnames.copy() #Copy the common field names\n",
    "    length = 8+len(imagetags) #Find the length of the image tag data frame\n",
    "    #Add each tag into the fieldnames, make sure it is labelled as an image tag\n",
    "    for tag in imagetags:\n",
    "        fn.append(tag+'_tag')\n",
    "    DF = pd.DataFrame() #The soon to be complete data set\n",
    "    for photo in data: #Get the data out with the associated column name\n",
    "        photodata = list(['0']*length) #blank row of data\n",
    "        md = photo['metadata'] #The photo's metadata\n",
    "        tags = md.get('imageTags','') #The photo's image tags by the API\n",
    "        #Set the variables\n",
    "        photodata[0] = photo['pageName']\n",
    "        photodata[1] = photo['extPostId']\n",
    "        photodata[2] = photo['extCreatedAt']\n",
    "        photodata[3] = md['imgHeight']\n",
    "        photodata[4] = md['imgWidth']\n",
    "        photodata[5] = photo['nFollowers']\n",
    "        photodata[6] = photo['nComments']\n",
    "        photodata[7] = photo['nLikes']\n",
    "        i = 8\n",
    "        for tag1 in imagetags:\n",
    "            for tag2 in tags:\n",
    "                if tag1 == tag2['value']:\n",
    "                    photodata[i] = 1 #tag2['confidence'] We decided to use binary data instead of the confidence score\n",
    "                    break\n",
    "            i = i+1\n",
    "        df_temp = pd.DataFrame(data = np.array(photodata).reshape((1,len(fn))), columns = fn) #turn our list into a dataframe\n",
    "        DF = DF.append(df_temp, ignore_index = True) #Combine this temp data frame with our complete data set\n",
    "    #Setting the type on the variables in the data frame\n",
    "    DF1 = DF.iloc[:,0:8]\n",
    "    DF2 = DF.iloc[:,8:]\n",
    "    DF2 = DF2.astype(float)\n",
    "    DF2 = DF2.round(decimals=0)\n",
    "    DF2 = DF2.astype(int)\n",
    "    sum1 = DF2.sum(axis=0)\n",
    "    badCols = list()\n",
    "    #Find the index of all the columns whose tag shows up less than 10 times\n",
    "    for index in range(len(sum1)):\n",
    "        if sum1[index]  < 10:\n",
    "            badCols.append(index)\n",
    "    #Remove the bad tags\n",
    "    DF2 = DF2.drop(DF2.columns[badCols], axis=1)\n",
    "    DF = pd.concat([DF1, DF2],axis=1)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hashtag_Data(fieldnames, data, hashtags):\n",
    "    #These next few functions all are copy and paste versions of the one above but for the other variables\n",
    "    fn = fieldnames.copy()\n",
    "    length = 8+len(hashtags)\n",
    "    for tag in hashtags:\n",
    "        fn.append(tag+'_ht')\n",
    "    DF = pd.DataFrame()\n",
    "    for photo in data: #Get the data out with the associated column name\n",
    "        photodata = list(['0']*length)\n",
    "        md = photo['metadata'] #The photo's metadata\n",
    "        ht = md['hashtags']\n",
    "        photodata[0] = photo['pageName']\n",
    "        photodata[1] = photo['extPostId']\n",
    "        photodata[2] = photo['extCreatedAt']\n",
    "        photodata[3] = md['imgHeight']\n",
    "        photodata[4] = md['imgWidth']\n",
    "        photodata[5] = photo['nFollowers']\n",
    "        photodata[6] = photo['nComments']\n",
    "        photodata[7] = photo['nLikes']\n",
    "        i = 8\n",
    "        for tag1 in hashtags:\n",
    "            for tag2 in ht:\n",
    "                if tag1 == tag2:\n",
    "                    photodata[i] = 1\n",
    "                    break\n",
    "            i = i+1\n",
    "        df_temp = pd.DataFrame(data = np.array(photodata).reshape((1,len(fn))), columns = fn)\n",
    "        DF = DF.append(df_temp, ignore_index = True)\n",
    "    DF1 = DF.iloc[:,0:8]\n",
    "    DF2 = DF.iloc[:,8:]\n",
    "    DF2 = DF2.astype(int)\n",
    "    sum1 = DF2.sum(axis=0)\n",
    "    badCols = list()\n",
    "    for index in range(len(sum1)):\n",
    "        if sum1[index]  < 10:\n",
    "            badCols.append(index)\n",
    "    DF2 = DF2.drop(DF2.columns[badCols], axis=1)\n",
    "    DF = pd.concat([DF1, DF2],axis=1)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Object_Data(fieldnames, data, imageobjects):    \n",
    "    fn = fieldnames.copy()\n",
    "    length = 8+len(imageobjects)\n",
    "    for objects in imageobjects:\n",
    "        fn.append(objects+'_obj')\n",
    "    DF = pd.DataFrame()\n",
    "    for photo in data: #Get the data out with the associated column name\n",
    "        photodata = list(['0']*length)\n",
    "        md = photo['metadata'] #The photo's metadata\n",
    "        objects = md['imageObjects']\n",
    "        photodata[0] = photo['pageName']\n",
    "        photodata[1] = photo['extPostId']\n",
    "        photodata[2] = photo['extCreatedAt']\n",
    "        photodata[3] = md['imgHeight']\n",
    "        photodata[4] = md['imgWidth']\n",
    "        photodata[5] = photo['nFollowers']\n",
    "        photodata[6] = photo['nComments']\n",
    "        photodata[7] = photo['nLikes']\n",
    "        i = 8\n",
    "        for object1 in imageobjects:\n",
    "            for object2 in objects:\n",
    "                if object1 == object2['name']:\n",
    "                    photodata[i] = 1 #object2['conf']\n",
    "                    break\n",
    "            i = i+1\n",
    "        df_temp = pd.DataFrame(data = np.array(photodata).reshape((1,len(fn))), columns = fn)\n",
    "        DF = DF.append(df_temp, ignore_index = True)\n",
    "    str_obj = DF.iloc[:,0:8] #creates dataset of just str data\n",
    "    int_obj = DF.iloc[:,8:]\n",
    "    int_obj = int_obj.astype(int) #creates dataset to convert datatypes to int\n",
    "    sum1 = int_obj.sum(axis=0) #get sums of columns\n",
    "    badCols = list()\n",
    "    for index in range(len(sum1)):\n",
    "        if sum1[index] < 5: #if object occurs less than 5 times, column name will be added to badCols list\n",
    "            badCols.append(index)\n",
    "    int_obj = int_obj.drop(int_obj.columns[badCols], axis=1) #names in badCols list will be dropped from original dataset\n",
    "    DF= pd.concat([str_obj, int_obj], axis=1) #combines str & int datasets\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Color_Data(fieldnames, data, imagecolors):\n",
    "    fn = fieldnames.copy()\n",
    "    length = 8+len(imagecolors)\n",
    "    for color in imagecolors:\n",
    "        fn.append(color)\n",
    "    DF = pd.DataFrame()\n",
    "    for photo in data: #Get the data out with the associated column name\n",
    "        photodata = list(['0']*length)\n",
    "        md = photo['metadata'] #The photo's metadata\n",
    "        colors = md['imageColors']\n",
    "        photodata[0] = photo['pageName']\n",
    "        photodata[1] = photo['extPostId']\n",
    "        photodata[2] = photo['extCreatedAt']\n",
    "        photodata[3] = md['imgHeight']\n",
    "        photodata[4] = md['imgWidth']\n",
    "        photodata[5] = photo['nFollowers']\n",
    "        photodata[6] = photo['nComments']\n",
    "        photodata[7] = photo['nLikes']\n",
    "        i = 8\n",
    "        for color1 in imagecolors:\n",
    "            for color2 in colors:\n",
    "                if color1 == color2['value']:\n",
    "                    photodata[i] = color2['confidence']\n",
    "                    break\n",
    "            i = i+1\n",
    "        df_temp = pd.DataFrame(data = np.array(photodata).reshape((1,len(fn))), columns = fn)\n",
    "        DF = DF.append(df_temp, ignore_index = True)\n",
    "    DF.columns = map(str.upper, DF.columns) #Capitalize all column names\n",
    "    #Here we are taking all the top 3 colors found by the API and mapping them to more general colors\n",
    "    #So instead of having both Maroon and Scarlet in the data set, we would label them both as Red\n",
    "    #This Color Group csv is in a separate file that needs to be read in.\n",
    "    with open(str(src_path_1)+'\\\\Color Group.csv', mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        mydict = {rows[0]:rows[1] for rows in reader}\n",
    "    DF=DF.rename(index=str,columns=mydict) #Rename all the columns in the data frame.  Now we could have multiple columns labelled Green\n",
    "    #create a list of color groups\n",
    "    color=['Pink','Purple','Red','Orange','Yellow','Green','Cyan','Blue','Brown','White','Grey','Black']\n",
    "    #change value tpe to float\n",
    "    for c in color:\n",
    "        DF[c]=DF[c].astype('float')\n",
    "    df=DF.transpose().reset_index().rename(columns={'index':'Color'}) #transpose dataset \n",
    "    df = df.groupby('Color').sum() #Group same colors together and sum their values together\n",
    "    DF=df.T #transpose back\n",
    "    cols = ['PageName', 'PostID', 'PostTime','Height','Width','Followers', 'Comments', 'Likes', 'Pink','Purple','Red','Orange','Yellow','Green','Cyan','Blue','Brown','White','Grey','Black']\n",
    "    DF = DF.reindex(columns=cols)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sylco(word):  #Syllable counter given only the spelling of a word\n",
    "    #This is code I pulled from https://eayd.in/?p=232\n",
    "    #There really are no good syllable counters for the english language based solely on the spelling of the words\n",
    "    #This code combines the 14 most common syllable counting rules we know to get the best prediction for the number\n",
    "    #of syllables a word would have\n",
    "    word = word.lower()\n",
    "\n",
    "    # exception_add are words that need extra syllables\n",
    "    # exception_del are words that need less syllables\n",
    "\n",
    "    exception_add = ['serious','crucial']\n",
    "    exception_del = ['fortunately','unfortunately', 'facebook']\n",
    "\n",
    "    co_one = ['cool','coach','coat','coal','count','coin','coarse','coup','coif','cook','coign','coiffe','coof','court']\n",
    "    co_two = ['coapt','coed','coinci']\n",
    "\n",
    "    pre_one = ['preach']\n",
    "\n",
    "    syls = 0 #added syllable number\n",
    "    disc = 0 #discarded syllable number\n",
    "\n",
    "    #1) if letters < 3 : return 1\n",
    "    if len(word) <= 3 :\n",
    "        syls = 1\n",
    "        return syls\n",
    "\n",
    "    #2) if doesn't end with \"ted\" or \"tes\" or \"ses\" or \"ied\" or \"ies\", discard \"es\" and \"ed\" at the end.\n",
    "    # if it has only 1 vowel or 1 set of consecutive vowels, discard. (like \"speed\", \"fled\" etc.)\n",
    "\n",
    "    if word[-2:] == \"es\" or word[-2:] == \"ed\" :\n",
    "        doubleAndtripple_1 = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "        if doubleAndtripple_1 > 1 or len(re.findall(r'[eaoui][^eaoui]',word)) > 1 :\n",
    "            if word[-3:] == \"ted\" or word[-3:] == \"tes\" or word[-3:] == \"ses\" or word[-3:] == \"ied\" or word[-3:] == \"ies\" :\n",
    "                pass\n",
    "            else :\n",
    "                disc+=1\n",
    "\n",
    "    #3) discard trailing \"e\", except where ending is \"le\"  \n",
    "\n",
    "    le_except = ['whole','mobile','pole','male','female','hale','pale','tale','sale','aisle','whale','while']\n",
    "\n",
    "    if word[-1:] == \"e\" :\n",
    "        if word[-2:] == \"le\" and word not in le_except :\n",
    "            pass\n",
    "\n",
    "        else :\n",
    "            disc+=1\n",
    "\n",
    "    #4) check if consecutive vowels exists, triplets or pairs, count them as one.\n",
    "\n",
    "    doubleAndtripple = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "    tripple = len(re.findall(r'[eaoui][eaoui][eaoui]',word))\n",
    "    disc+=doubleAndtripple + tripple\n",
    "\n",
    "    #5) count remaining vowels in word.\n",
    "    numVowels = len(re.findall(r'[eaoui]',word))\n",
    "\n",
    "    #6) add one if starts with \"mc\"\n",
    "    if word[:2] == \"mc\" :\n",
    "        syls+=1\n",
    "\n",
    "    #7) add one if ends with \"y\" but is not surrouned by vowel\n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\" :\n",
    "        syls +=1\n",
    "\n",
    "    #8) add one if \"y\" is surrounded by non-vowels and is not in the last word.\n",
    "\n",
    "    for i,j in enumerate(word) :\n",
    "        if j == \"y\" :\n",
    "            if (i != 0) and (i != len(word)-1) :\n",
    "                if word[i-1] not in \"aeoui\" and word[i+1] not in \"aeoui\" :\n",
    "                    syls+=1\n",
    "\n",
    "    #9) if starts with \"tri-\" or \"bi-\" and is followed by a vowel, add one.\n",
    "\n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    #10) if ends with \"-ian\", should be counted as two syllables, except for \"-tian\" and \"-cian\"\n",
    "\n",
    "    if word[-3:] == \"ian\" : \n",
    "    #and (word[-4:] != \"cian\" or word[-4:] != \"tian\") :\n",
    "        if word[-4:] == \"cian\" or word[-4:] == \"tian\" :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #11) if starts with \"co-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:2] == \"co\" and word[2] in 'eaoui' :\n",
    "\n",
    "        if word[:4] in co_two or word[:5] in co_two or word[:6] in co_two :\n",
    "            syls+=1\n",
    "        elif word[:4] in co_one or word[:5] in co_one or word[:6] in co_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #12) if starts with \"pre-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:3] == \"pre\" and word[3] in 'eaoui' :\n",
    "        if word[:6] in pre_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #13) check for \"-n't\" and cross match with dictionary to add syllable.\n",
    "\n",
    "    negative = [\"doesn't\", \"isn't\", \"shouldn't\", \"couldn't\",\"wouldn't\"]\n",
    "\n",
    "    if word[-3:] == \"n't\" :\n",
    "        if word in negative :\n",
    "            syls+=1\n",
    "        else :\n",
    "            pass   \n",
    "\n",
    "    #14) Handling the exceptional words.\n",
    "\n",
    "    if word in exception_del :\n",
    "        disc+=1\n",
    "\n",
    "    if word in exception_add :\n",
    "        syls+=1     \n",
    "\n",
    "    # calculate the output\n",
    "    return numVowels - disc + syls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Readability_Data(fieldnames, data):\n",
    "    #Similar start to before by making a fieldname list and an empty data frame\n",
    "    fn = fieldnames.copy()\n",
    "    length = 9\n",
    "    fn.append('Flesch RE')\n",
    "    DF = pd.DataFrame()\n",
    "    for photo in data: #Get the data out with the associated column name\n",
    "        text = photo['rawText'].replace('\\u2063','') #For each raw caption remove the hidden character that appears whenever you\n",
    "        #use a period\n",
    "        text = text.lower() #Make all the words lower case, so that we can better cleanse it\n",
    "        text = re.sub(r'[^a-z\\s#@]','',text) #Remove everything that isn't a letter or a # or @\n",
    "        words = text.split() #Make a list of all the words\n",
    "        i = 0\n",
    "        while i < len(words):\n",
    "            if words[i][0] == '#' or words[i][0] == '@': #Remove # and @ words. It's really hard to count syllables on these words\n",
    "                words.pop(i)\n",
    "                i = i - 1\n",
    "            i = i + 1\n",
    "        photodata = list(['0']*length)\n",
    "        md = photo['metadata'] #The photo's metadata\n",
    "        syllb = 0.0 #The reading score is a float but everything in the formula is an int, so make syllb a float to get the\n",
    "                    #Correct answer\n",
    "        row = np.array([[0,0,0,0,0]])\n",
    "        for word in words:\n",
    "            syllb += sylco(word)\n",
    "        photodata[0] = photo['pageName']\n",
    "        photodata[1] = photo['extPostId']\n",
    "        photodata[2] = photo['extCreatedAt']\n",
    "        photodata[3] = md['imgHeight']\n",
    "        photodata[4] = md['imgWidth']\n",
    "        photodata[5] = photo['nFollowers']\n",
    "        photodata[6] = photo['nComments']\n",
    "        photodata[7] = photo['nLikes']\n",
    "        #If there is no caption, place a NULL there instead\n",
    "        if len(words) == 0:\n",
    "            photodata[8] = np.nan\n",
    "        else:\n",
    "            photodata[8] = 206.835-1.015*len(words)-84.6*(syllb/len(words))\n",
    "        df_temp = pd.DataFrame(data = np.array(photodata).reshape((1,len(fn))), columns = fn)\n",
    "        DF = DF.append(df_temp, ignore_index = True)\n",
    "    DF['Flesch RE'] = DF['Flesch RE'].astype(float)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PHash_Data(fieldnames, data):\n",
    "    fn = fieldnames.copy()\n",
    "    length = 9\n",
    "    fn.append('PHash')\n",
    "    DF = pd.DataFrame()\n",
    "    for photo in data: #Get the data out with the associated column name\n",
    "        photodata = list(['0']*length)\n",
    "        md = photo['metadata'] #The photo's metadata\n",
    "        photodata[0] = photo['pageName']\n",
    "        photodata[1] = photo['extPostId']\n",
    "        photodata[2] = photo['extCreatedAt']\n",
    "        photodata[3] = md['imgHeight']\n",
    "        photodata[4] = md['imgWidth']\n",
    "        photodata[5] = photo['nFollowers']\n",
    "        photodata[6] = photo['nComments']\n",
    "        photodata[7] = photo['nLikes']\n",
    "        photodata[8] = md['imagePHash']\n",
    "        df_temp = pd.DataFrame(data = np.array(photodata).reshape((1,len(fn))), columns = fn)\n",
    "        DF = DF.append(df_temp, ignore_index = True)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DateTime_Parts(data): #Creates a bunch of different date times in boolean (0/1) form. Only read in Final data with a \"PostTime\" variable\n",
    "    data['date_series'] = pd.to_datetime(data['PostTime'])\n",
    "    data['yearofpost'] = data['date_series'].dt.year\n",
    "    data['monthofpost'] = data['date_series'].dt.month\n",
    "    data['hourofpost'] = data['date_series'].dt.hour\n",
    "    data['minuteofpost'] = data['date_series'].dt.minute\n",
    "    data['quarterofpost'] = data['date_series'].dt.quarter\n",
    "    data['JanuaryPost'] = np.where(data['monthofpost'] == 1, 1,0)\n",
    "    data['FebuaryPost'] = np.where(data['monthofpost'] == 2, 1,0)\n",
    "    data['MarchPost'] = np.where(data['monthofpost'] == 3, 1,0)\n",
    "    data['AprilPost'] = np.where(data['monthofpost'] == 4, 1,0)\n",
    "    data['MayPost'] = np.where(data['monthofpost'] == 5, 1,0)\n",
    "    data['JunePost'] = np.where(data['monthofpost'] == 6, 1,0)\n",
    "    data['JulyPost'] = np.where(data['monthofpost'] == 7, 1,0)\n",
    "    data['AugustPost'] = np.where(data['monthofpost'] == 8, 1,0)\n",
    "    data['SeptemberPost'] = np.where(data['monthofpost'] == 9, 1,0)\n",
    "    data['OctoberPost'] = np.where(data['monthofpost'] == 10, 1,0)\n",
    "    data['NovemberPost'] = np.where(data['monthofpost'] == 11, 1,0)\n",
    "    data['DecemberPost'] = np.where(data['monthofpost'] == 12, 1,0)\n",
    "    conditions = [\n",
    "        (data['hourofpost'] <= 5) | (data['hourofpost'] > 22),\n",
    "        (data['hourofpost'] > 5) & (data['hourofpost'] <= 12),\n",
    "        (data['hourofpost'] > 12) & (data['hourofpost'] <= 17),\n",
    "        (data['hourofpost'] > 17) & (data['hourofpost'] <= 22)]\n",
    "    choices = ['11pm to 5am', '6am to 12pm', '1pm to 5pm', '6pm to 10pm']\n",
    "    data['TimeofDay'] = np.select(conditions, choices, default='N/A')\n",
    "    data['11pm to 5am'] = np.where(data['TimeofDay']=='11pm to 5am',1,0)\n",
    "    data['6am to 12pm'] = np.where(data['TimeofDay']=='6am to 12pm',1,0)\n",
    "    data['1pm to 5pm'] = np.where(data['TimeofDay']=='1pm to 5pmm',1,0)\n",
    "    data['6pm to 10pm'] = np.where(data['TimeofDay']=='6pm to 10pm',1,0)\n",
    "    data = data.drop(columns = ['TimeofDay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SchoolPart(df):\n",
    "    conditions = [\n",
    "        df['Flesch RE'] >= 100,\n",
    "        (df['Flesch RE'] < 100) & (df['Flesch RE'] >= 90),\n",
    "        (df['Flesch RE'] < 90) & (df['Flesch RE'] >= 80),\n",
    "        (df['Flesch RE'] < 80) & (df['Flesch RE'] >= 70),\n",
    "        (df['Flesch RE'] < 70) & (df['Flesch RE'] >= 60),\n",
    "        (df['Flesch RE'] < 60) & (df['Flesch RE'] >= 50),\n",
    "        (df['Flesch RE'] < 50) & (df['Flesch RE'] >= 30),\n",
    "        (df['Flesch RE'] < 30) & (df['Flesch RE'] >= 0),\n",
    "        df['Flesch RE'] < 0]\n",
    "    choices = ['4th or Below', '5th', '6th', '7th', '8th or 9th', '10th - 12th', 'College', 'College Graduate', 'Post Graduate Studies']\n",
    "    df['SchoolYearRead'] = np.select(conditions, choices, default='NULL')\n",
    "    conditions = [\n",
    "        df['Flesch RE'] >= 90,\n",
    "        (df['Flesch RE'] < 90) & (df['Flesch RE'] >= 60),\n",
    "        (df['Flesch RE'] < 60) & (df['Flesch RE'] >= 50),\n",
    "        (df['Flesch RE'] < 50) & (df['Flesch RE'] >= 30),\n",
    "        (df['Flesch RE'] < 30) & (df['Flesch RE'] >= 0),\n",
    "        df['Flesch RE'] < 0]\n",
    "    choices = ['Elementary and Below', 'Middle', 'High', 'College', 'College Grad', 'Post Grad']\n",
    "    df['SchoolGroupRead'] = np.select(conditions, choices, default='NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos = Column_Headers(imagetags, hashtags, imageobjects, imagecolors)\n",
    "get_tag = Image_Tag_Data(fieldnames, photos, imagetags)\n",
    "get_hash = Hashtag_Data(fieldnames, photos, hashtags)\n",
    "DFmerge1 = pd.merge(get_tag, get_hash, how = 'left', on = ['PageName', 'PostID', 'PostTime', 'Height', 'Width', 'Followers', 'Comments', 'Likes'])\n",
    "del [[get_tag,get_hash]]\n",
    "gc.collect()\n",
    "get_obj = Image_Object_Data(fieldnames, photos, imageobjects)\n",
    "DFmerge2 = pd.merge(DFmerge1, get_obj, how = 'left', on = ['PageName', 'PostID', 'PostTime', 'Height', 'Width', 'Followers', 'Comments', 'Likes'])\n",
    "del [[get_obj,DFmerge1]]\n",
    "gc.collect()\n",
    "get_color = Image_Color_Data(fieldnames, photos, imagecolors)\n",
    "DFmerge3 = pd.merge(DFmerge2, get_color, how = 'left', on = ['PageName', 'PostID', 'PostTime', 'Height', 'Width', 'Followers', 'Comments', 'Likes'])\n",
    "del [[get_color,DFmerge2]]\n",
    "gc.collect()\n",
    "get_readability = Readability_Data(fieldnames, photos)\n",
    "DFmerge4 = pd.merge(DFmerge3, get_readability, how = 'left', on = ['PageName', 'PostID', 'PostTime', 'Height', 'Width', 'Followers', 'Comments', 'Likes'])\n",
    "del [[get_readability,DFmerge3]]\n",
    "gc.collect()\n",
    "get_phash = PHash_Data(fieldnames, photos)\n",
    "DFfull = pd.merge(DFmerge4, get_phash, how = 'left', on = ['PageName', 'PostID', 'PostTime', 'Height', 'Width', 'Followers', 'Comments', 'Likes'])\n",
    "del [[get_phash,DFmerge4]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFfull['Followers'] = pd.to_numeric(DFfull['Followers'])\n",
    "DFfull['Likes'] = pd.to_numeric(DFfull['Likes'])\n",
    "DFfull['Comments'] = pd.to_numeric(DFfull['Comments'])\n",
    "DFfull['Engagement_Rate'] = ((DFfull['Comments'] + DFfull['Likes']) / DFfull['Followers']) * 100\n",
    "DateTime_Parts(DFfull)\n",
    "SchoolPart(DFfull)\n",
    "DFfull.to_pickle('Full_Cortex_Dataset.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
